{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZFEH+zzJjAXlLE2VOzIi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Y4S1-Deep-Learning/Leaf-Desease-Detection---Supervised-Learning/blob/aathif/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PorUsKx8TO0k"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries and mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List files in the specified directory\n",
        "!ls \"/content/drive/My Drive/DLProject\"\n",
        "!ls \"/content/drive/My Drive/DLProject/Dataset\"\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Display the TensorFlow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Plot random images from the dataset\n",
        "plt.figure(figsize=(12, 12))\n",
        "path = \"/content/drive/My Drive/DLProject/Dataset\"\n",
        "for i in range(1, 17):\n",
        "    plt.subplot(4, 4, i)\n",
        "    plt.tight_layout()\n",
        "    rand_img = imread(path + '/' + random.choice(sorted(os.listdir(path)))\n",
        "    plt.imshow(rand_img)\n",
        "    plt.xlabel(rand_img.shape[1], fontsize=10)\n",
        "    plt.ylabel(rand_img.shape[0], fontsize=10)\n",
        "\n",
        "# Define a function to convert an image to an array\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, (256, 256))\n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define directory path\n",
        "dir = \"/content/drive/My Drive/DLProject\"\n",
        "\n",
        "# Initialize lists to store image data and labels\n",
        "image_list, label_list = [], []\n",
        "\n",
        "# Define all possible labels and their corresponding binary labels\n",
        "all_labels = ['Apple Scab Leaf', 'Apple leaf', 'Apple rust leaf', ...]  # List of labels\n",
        "binary_labels = [0, 1, 2, 3, 4, 5, ...]  # Corresponding binary labels\n",
        "\n",
        "# Initialize a variable to keep track of labels\n",
        "temp = -1\n",
        "\n",
        "# Loop through the directories and images\n",
        "for directory in ['Dataset']:\n",
        "    plant_image_list = listdir(f\"{dir}/{directory}\")\n",
        "    temp += 1\n",
        "    for files in plant_image_list:\n",
        "        image_path = f\"{dir}/{directory}/{files}\"\n",
        "        image_list.append(convert_image_to_array(image_path))\n",
        "        label_list.append(binary_labels[temp])\n",
        "\n",
        "# Create a DataFrame to count the occurrences of each label\n",
        "label_counts = pd.DataFrame(label_list).value_counts()\n",
        "label_counts.head()\n",
        "\n",
        "# Check the shape of the first image in the list\n",
        "image_list[0].shape\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state=10)\n",
        "\n",
        "# Normalize the image data and reshape\n",
        "x_train = np.array(x_train, dtype=np.float16) / 255.0\n",
        "x_test = np.array(x_test, dtype=np.float16) / 255.0\n",
        "x_train = x_train.reshape(-1, 256, 256, 3)\n",
        "x_test = x_test.reshape(-1, 256, 256, 3)\n",
        "\n",
        "# Convert labels to categorical format\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(256, 256, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=10)\n",
        "\n",
        "# Define training parameters\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
        "\n",
        "# Plot the model accuracy over epochs\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history.history['accuracy'], color='r')\n",
        "plt.plot(history.history['val_accuracy'], color='b')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n",
        "\n",
        "# Calculate the model's accuracy on the test data\n",
        "print(\"Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1] * 100}\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Display an image from the test data\n",
        "img = array_to_img(x_test[11])\n",
        "img\n",
        "\n",
        "# Display the original and predicted labels for a specific test data point\n",
        "print(\"Original Label:\", all_labels[np.argmax(y_test[11])])\n",
        "print(\"Predicted Label:\", all_labels[np.argmax(y_pred[11])])\n",
        "print(y_pred[2])\n",
        "\n",
        "# Display the original and predicted labels for a range of test data points\n",
        "for i in range(50):\n",
        "    print(all_labels[np.argmax(y_test[i])], \"-\", all_labels[np.argmax(y_pred[i])])\n",
        "\n",
        "# Save the model to Google Drive\n",
        "model.save(\"/content/drive/My Drive/DLProject/Model\")\n"
      ]
    }
  ]
}